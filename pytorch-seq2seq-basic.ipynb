{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "65b932b1-2187-45f8-9950-aded9ec6c933"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "GeForce GTX 1080 Ti\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "USE_CUDA=torch.cuda.is_available()\n",
    "device=torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5e01fa13-27dc-4f31-8b5c-a8ddb5d2eb52"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "corpus_dir=\"data/cornell movie-dialogs corpus\"\n",
    "def printLines(file,n=10):\n",
    "    with open(file,\"rb\") as datafile:\n",
    "        lines=datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "printLines(os.path.join(corpus_dir,\"movie_lines.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3e949896-8814-4aa7-a64e-5c1d86a455cb"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus...\n",
      "{'characterId': 'u2532', 'text': \"His wife's influence.\\n\", 'character': 'COULMIER', 'lineId': 'L456595', 'movieId': 'm164'}\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "datafile=os.path.join(corpus_dir,\"formatted_movie_lines.txt\")\n",
    "delimiter=\"\\t\"\n",
    "delimiter=str(codecs.decode(delimiter,\"unicode_escape\"))\n",
    "\n",
    "lines={}\n",
    "conversations={}\n",
    "MOVIE_LINES_FIELDS=[\"lineId\",\"characterId\",\"movieId\",\"character\",\"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS=[\"character1Id\",\"character2Id\",\"movieId\",\"utteranceIds\"]\n",
    "\n",
    "print(\"Processing corpus...\")\n",
    "def loadLines(fileName,fields):\n",
    "    lines={}\n",
    "    with open(fileName,\"r\",encoding=\"iso-8859-1\") as f:\n",
    "        for line in f:\n",
    "            values=line.split(\" +++$+++ \")\n",
    "            lineObj={}\n",
    "            for i,field in enumerate(fields):\n",
    "                lineObj[field]=values[i]\n",
    "            lines[lineObj[\"lineId\"]]=lineObj\n",
    "    return lines\n",
    "lines=loadLines(os.path.join(corpus_dir,\"movie_lines.txt\"),MOVIE_LINES_FIELDS)\n",
    "lines_keys=list(lines.keys())\n",
    "print(lines[lines_keys[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "45c9b2bd-d274-4ea3-9cff-9c82a6f86a53"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'utteranceIds': \"['L194', 'L195', 'L196', 'L197']\\n\", 'lines': [{'characterId': 'u0', 'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n', 'character': 'BIANCA', 'lineId': 'L194', 'movieId': 'm0'}, {'characterId': 'u2', 'text': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\", 'character': 'CAMERON', 'lineId': 'L195', 'movieId': 'm0'}, {'characterId': 'u0', 'text': 'Not the hacking and gagging and spitting part.  Please.\\n', 'character': 'BIANCA', 'lineId': 'L196', 'movieId': 'm0'}, {'characterId': 'u2', 'text': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\", 'character': 'CAMERON', 'lineId': 'L197', 'movieId': 'm0'}], 'character2Id': 'u2', 'character1Id': 'u0', 'movieId': 'm0'}\n"
     ]
    }
   ],
   "source": [
    "def loadConversations(fileName,lines,fields):\n",
    "    conversations=[]\n",
    "    with open(fileName,\"r\",encoding=\"iso-8859-1\") as f:\n",
    "        for line in f:\n",
    "            values=line.split(\" +++$+++ \")\n",
    "            convObj={}\n",
    "            for i,field in enumerate(fields):\n",
    "                convObj[field]=values[i]\n",
    "            linesIds=eval(convObj[\"utteranceIds\"])\n",
    "            convObj[\"lines\"]=[]\n",
    "            for lineId in linesIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "conversations=loadConversations(os.path.join(corpus_dir,\"movie_conversations.txt\"),lines,MOVIE_CONVERSATIONS_FIELDS)\n",
    "print(conversations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "6e83c80c-0b51-4067-8eae-e431aaea6560"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing newly formatted file...\n",
      "Sample lines from file:\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\r\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\r\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\r\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\r\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\r\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\r\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\r\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\r\\n'\n",
      "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\r\\n\"\n",
      "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def extractSentencePairs(conversations):\n",
    "    qa_pairs=[]\n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation[\"lines\"])-1):\n",
    "            inputLine=conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine=conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine,targetLine])\n",
    "    return qa_pairs\n",
    "print(\"Writing newly formatted file...\")\n",
    "with open(datafile,\"w\",encoding=\"utf-8\") as outputfile:\n",
    "    writer=csv.writer(outputfile,delimiter=delimiter,lineterminator=\"\\n\")\n",
    "    pairs=extractSentencePairs(conversations)\n",
    "    for pair in pairs:\n",
    "        writer.writerow(pair)\n",
    "print(\"Sample lines from file:\")\n",
    "printLines(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "066daf18-0bca-4814-856f-8252567f599e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines from :  data/cornell movie-dialogs corpus\\formatted_movie_lines.txt\n",
      "Counted words: 18008\n",
      "['there .', 'where ?']\n",
      "['you have my word . as a gentleman', 'you re sweet .']\n",
      "['hi .', 'looks like things worked out tonight huh ?']\n",
      "['you know chastity ?', 'i believe we share an art instructor']\n",
      "['have fun tonight ?', 'tons']\n",
      "['well no . . .', 'then that s all you had to say .']\n",
      "['then that s all you had to say .', 'but']\n",
      "['but', 'you always been this selfish ?']\n",
      "['do you listen to this crap ?', 'what crap ?']\n",
      "['what good stuff ?', 'the real you .']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "PAD_token=0\n",
    "SOS_token=1\n",
    "EOS_token=2\n",
    "MAX_LENGTH=10\n",
    "\n",
    "corpus_name = \"cornell movie-dialogs corpus\"\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self,name):\n",
    "        self.name=name\n",
    "        self.trimmed=False\n",
    "        self.word2index={}\n",
    "        self.index2word={PAD_token:\"PAD\",SOS_token:\"SOS\",EOS_token:\"EOS\"}\n",
    "        self.word2count={}\n",
    "        self.num_words=3\n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word]=self.num_words\n",
    "            self.index2word[self.num_words]=word\n",
    "            self.num_words+=1\n",
    "            self.word2count[word]=1\n",
    "        else:\n",
    "            self.word2count[word]+=1\n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "    def trim(self,min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed=True\n",
    "        keep_words=[]\n",
    "        for k,v in self.word2count.items():\n",
    "            if v>=min_count:\n",
    "                keep_words.append(k)\n",
    "        print(\"Keep words {}/{} = {:.4f}\".format(\n",
    "                len(keep_words),\n",
    "                len(self.word2count),\n",
    "                len(keep_words)/len(self.word2count)))\n",
    "        \n",
    "        self.word2count={}\n",
    "        self.word2index={}\n",
    "        self.index2word={PAD_token:\"PAD\",SOS_token:\"SOS\",EOS_token:\"EOS\"}\n",
    "        self.num_words=3\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )            \n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def readVocs(datafile,corpus_name):\n",
    "    print(\"Reading lines from : \",datafile)\n",
    "    lines=open(datafile,encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "    pairs=[[normalizeString(s) for s in line.split(\"\\t\")]for line in lines]\n",
    "    voc=Voc(corpus_name)\n",
    "    return voc,pairs\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(\" \"))<MAX_LENGTH and len(p[1].split(\" \"))<MAX_LENGTH\n",
    "def filterPairs(pairs):\n",
    "    return [p for p in pairs if filterPair(p)]\n",
    "\n",
    "def loadPrepareData(corpus_name,datafile):\n",
    "    voc,pairs=readVocs(datafile,corpus_name)\n",
    "    pairs=filterPairs(pairs)\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\",voc.num_words)\n",
    "    return voc,pairs\n",
    "\n",
    "voc,pairs=loadPrepareData(corpus_name,datafile)\n",
    "for pair in pairs[:10]:\n",
    "    print(pair)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a1fd339a-7bdd-4dbf-8464-0f9ba2e3165a"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep words 7823/18005 = 0.4345\n",
      "Trimmed from 64271 to 53165, 0.8272 in total.\n"
     ]
    }
   ],
   "source": [
    "MIN_COUNT=3\n",
    "def trimRareWords(voc,pairs,MIN_COUNT):\n",
    "    voc.trim(MIN_COUNT)\n",
    "    keep_pairs=[]\n",
    "    for pair in pairs:\n",
    "        input_sentence=pair[0]\n",
    "        output_sentence=pair[1]\n",
    "        keep_input=True\n",
    "        keep_output=True\n",
    "        for word in input_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input=False\n",
    "                break\n",
    "        for word in output_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output=False\n",
    "                break\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "    print(\"Trimmed from {} to {}, {:.4f} in total.\".format(len(pairs),len(keep_pairs),len(keep_pairs)/len(pairs)))\n",
    "    return keep_pairs\n",
    "pairs=trimRareWords(voc,pairs,MIN_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what happened . . . ?', 'don t ask .'], ['i put you on the floor .', 'oh .'], ['sleeping in the back .', 'she asked me to pick her up .'], ['great .', 'actually . i could only help him .'], ['wow !', 'wendy !']]\n",
      "tensor([[1347, 1819, 4537,  308, 2216],\n",
      "        [1157, 4334, 4580, 5230, 2879],\n",
      "        [7691, 1239, 1913, 5859,    2],\n",
      "        [3237, 1295, 1479, 2879,    0],\n",
      "        [6400, 2961,    2,    2,    0],\n",
      "        [1792,  416,    0,    0,    0],\n",
      "        [6459, 1479,    0,    0,    0],\n",
      "        [ 184,    2,    0,    0,    0],\n",
      "        [1479,    0,    0,    0,    0],\n",
      "        [   2,    0,    0,    0,    0]])\n",
      "tensor([10,  8,  5,  5,  3])\n",
      "tensor([[ 298, 5610, 3052, 7590, 7691],\n",
      "        [3688, 4580, 2406, 7035, 4235],\n",
      "        [2406, 5663,    2, 2609, 6278],\n",
      "        [   2, 1479,    0, 1479, 1295],\n",
      "        [   0,    2,    0,    2, 7213],\n",
      "        [   0,    0,    0,    0, 1479],\n",
      "        [   0,    0,    0,    0,    2]])\n",
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 0, 1, 1],\n",
      "        [0, 1, 0, 1, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1]], dtype=torch.uint8)\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def indexFromSentence(voc,sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(\" \")]+[EOS_token]\n",
    "def zeroPadding(l,fill_value=PAD_token):\n",
    "    return list(itertools.zip_longest(*l,fillvalue=fill_value))\n",
    "def binaryMatrix(l,value=PAD_token):\n",
    "    m=[]\n",
    "    for i,seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token==value:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "def inputVar(input_batch,voc):\n",
    "    indexs_batch=[indexFromSentence(voc,sentence) for sentence in input_batch]\n",
    "    length=torch.tensor([len(index) for index in indexs_batch])\n",
    "    padList=zeroPadding(indexs_batch)\n",
    "    padVar=torch.LongTensor(padList)\n",
    "    return padVar,length\n",
    "def outputVar(output_batch,voc):\n",
    "    indexs_batch=[indexFromSentence(voc,sentence) for sentence in output_batch]\n",
    "    max_target_len=max([len(index) for index in indexs_batch])\n",
    "    padList=zeroPadding(indexs_batch)\n",
    "    mask=binaryMatrix(padList)\n",
    "    mask=torch.ByteTensor(mask)\n",
    "    padVar=torch.LongTensor(padList)\n",
    "    return padVar,mask,max_target_len\n",
    "\n",
    "import time\n",
    "def batch2TrianData(voc,pair_batch):\n",
    "    start=time.time()\n",
    "    pair_batch.sort(key=lambda x:len(x[0].split(\" \")),reverse=True)\n",
    "    input_batch,output_batch=[],[]\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp,lengths=inputVar(input_batch,voc)\n",
    "    output,mask,max_target_len=outputVar(output_batch,voc)\n",
    "    return inp,lengths,output,mask,max_target_len\n",
    "\n",
    "small_batchsize=5\n",
    "print([np.random.choice(pairs) for _ in range(small_batchsize)])\n",
    "\n",
    "inp,lengths,output,mask,max_target_len=batch2TrianData(voc,\n",
    "                                                       [np.random.choice(pairs) \n",
    "                                                        for _ in range(small_batchsize)])\n",
    "print(inp)\n",
    "print(lengths)\n",
    "print(output)\n",
    "print(mask)\n",
    "print(max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7826, 500])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "hidden_size=500\n",
    "\n",
    "embedding=nn.Embedding(voc.num_words,hidden_size)\n",
    "print(embedding.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,hidden_size,embedding,n_layers=1,dropout=0):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.embedding=embedding\n",
    "        self.hidden_size=hidden_size\n",
    "        self.n_layers=n_layers\n",
    "        \n",
    "        self.gru=nn.GRU(hidden_size,hidden_size,n_layers,\n",
    "                        dropout=(0 if n_layers==1 else dropout),bidirectional=True)\n",
    "        \n",
    "    def forward(self,input_seq,input_length,hidden=None):\n",
    "        embed=self.embedding(input_seq)\n",
    "        packed=torch.nn.utils.rnn.pack_padded_sequence(embed,input_length)\n",
    "        outputs,hidden=self.gru(packed,hidden)\n",
    "        outputs,_=torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs=outputs[:,:,:self.hidden_size]+outputs[:,:,self.hidden_size:]\n",
    "        return outputs,hidden\n",
    "_encoder=EncoderRNN(hidden_size,embedding,n_layers=2)  \n",
    "_encoder_outputs,_encoder_hidden=_encoder.forward(inp,lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self,method,hidden_size):\n",
    "        super(Attn,self).__init__()\n",
    "        self.method=method\n",
    "        if self.method not in [\"dot\",\"general\",\"concat\"]:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size=hidden_size\n",
    "    def dot_score(self,hidden,encoder_output):\n",
    "        tmp=hidden*encoder_output\n",
    "        tmp2=torch.sum(tmp,dim=2)\n",
    "        return tmp2\n",
    "    def forward(self,hidden,encoder_output):\n",
    "        if self.method==\"dot\":\n",
    "            attn_energies=self.dot_score(hidden,encoder_output)\n",
    "        attn_energies=attn_energies.t()\n",
    "        return F.softmax(attn_energies,dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self,attn_model,embedding,hidden_size,output_size,n_layers=1,dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN,self).__init__()\n",
    "        \n",
    "        self.attn_model=attn_model\n",
    "        self.hidden_size=hidden_size\n",
    "        self.output_size=output_size\n",
    "        self.n_layers=n_layers\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        self.embedding=embedding\n",
    "        self.embedding_dropout=nn.Dropout(dropout)\n",
    "        self.gru=nn.GRU(hidden_size,hidden_size,n_layers,dropout=(0 if n_layers==1 else dropout))\n",
    "        self.concat=nn.Linear(hidden_size*2,hidden_size)\n",
    "        self.out=nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "        self.attn=Attn(attn_model,hidden_size)\n",
    "    def forward(self,input_step,last_hidden,encoder_outputs):\n",
    "        embedded=self.embedding(input_step)\n",
    "        embedded=self.embedding_dropout(embedded)\n",
    "        rnn_output,hidden=self.gru(embedded,last_hidden)\n",
    "\n",
    "        attn_weights=self.attn(rnn_output,encoder_outputs)\n",
    "        context=attn_weights.bmm(encoder_outputs.transpose(0,1))\n",
    "        rnn_output=rnn_output.squeeze(0)\n",
    "        context=context.squeeze(1)\n",
    "        concat_input=torch.cat((rnn_output,context),1)\n",
    "        concat_output=torch.tanh(self.concat(concat_input))\n",
    "        \n",
    "        output=self.out(concat_output)\n",
    "        output=F.softmax(output,dim=1)\n",
    "        \n",
    "        return output,hidden\n",
    "_decoder=LuongAttnDecoderRNN(\"dot\",embedding,hidden_size,voc.num_words,n_layers=2)\n",
    "_decoder_input_step=torch.LongTensor([[SOS_token for _ in range(small_batchsize)]])\n",
    "_decoder_hidden=_encoder_hidden[:_decoder.n_layers]\n",
    "_decoder_output,_decoder_hidden=_decoder.forward(_decoder_input_step,_decoder_hidden,_encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp,target,mask):\n",
    "    nTotal=mask.sum()\n",
    "    crossEntropy=-torch.log(torch.gather(inp,1,target.view(-1,1)).squeeze(1))\n",
    "    loss=crossEntropy.masked_select(mask).mean()\n",
    "    loss=loss.to(device)\n",
    "    return loss,nTotal.item()\n",
    "\n",
    "def train(input_variable,lengths,target_variable,mask,max_target_len,encoder,decoder,embedding,\n",
    "         encoder_optimizer,decoder_optimizer,batch_size,clip,max_length=MAX_LENGTH):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_variable=input_variable.to(device)\n",
    "    lengths=lengths.to(device)\n",
    "    target_variable=target_variable.to(device)\n",
    "    mask=mask.to(device)\n",
    "    \n",
    "    loss=0\n",
    "    print_losses=[]\n",
    "    n_totals=0\n",
    "    \n",
    "    encoder_outputs,encoder_hidden=encoder(input_variable,lengths)\n",
    "    \n",
    "    decoder_input=torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input=decoder_input.to(device)\n",
    "    \n",
    "    decoder_hidden=encoder_hidden[:decoder.n_layers]\n",
    "    \n",
    "    use_teacher_forcing=True if np.random.random()<teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            \n",
    "            decoder_input=target_variable[t].view(1,-1)\n",
    "            \n",
    "            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item()*nTotal)\n",
    "            \n",
    "            n_totals+=nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            \n",
    "            _,topi=decoder_output.topk(1)\n",
    "            \n",
    "            decoder_input=torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input=decoder_input.to(device)\n",
    "            \n",
    "            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item()*nTotal)\n",
    "            n_totals+=nTotal\n",
    "    loss.backward()\n",
    "    \n",
    "    _=torch.nn.utils.clip_grad_norm_(encoder.parameters(),clip)\n",
    "    _=torch.nn.utils.clip_grad_norm_(decoder.parameters(),clip)\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(print_losses)/n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self,encoder,decoder):\n",
    "        super(GreedySearchDecoder,self).__init__()\n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "    def forward(self,input_seq,input_length,max_length):\n",
    "        encoder_output,encoder_hidden=self.encoder(input_seq,input_length)\n",
    "        decoder_hidden=encoder_hidden[:self.decoder.n_layers]\n",
    "        \n",
    "        decoder_input=torch.ones(1,1,device=device,dtype=torch.long)*SOS_token\n",
    "        \n",
    "        all_tokens=torch.zeros([0],device=device,dtype=torch.long)\n",
    "        all_scores=torch.zeros([0],device=device)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            decoder_output,decoder_hidden=self.decoder(decoder_input,decoder_hidden,encoder_output)\n",
    "            decoder_scores,decoder_input=torch.max(decoder_output,dim=1)\n",
    "            \n",
    "            all_tokens=torch.cat((all_tokens,decoder_input),dim=0)\n",
    "            all_scores=torch.cat((all_scores,decoder_scores),dim=0)\n",
    "            \n",
    "            decoder_input=torch.unsqueeze(decoder_input,0)\n",
    "        return all_tokens,all_scores\n",
    "    \n",
    "def trainIters(model_name,voc,pairs,encoder,decoder,encoder_optimizer,decoder_optimizer,\n",
    "              embedding,encoder_n_layers,decoder_n_layers,save_dir,n_iteration,batch_size,\n",
    "              print_every,save_every,clip,corpus_name,loadFileName):\n",
    "    '''print(\"Loading batches...\")\n",
    "    train_batches=[batch2TrianData(voc,[random.choice(pairs) for _ in range(batch_size)])\n",
    "                  for _ in range(n_iteration)]'''\n",
    "    \n",
    "    print(\"Initializing...\")\n",
    "    start_iteration=1\n",
    "    print_loss=0\n",
    "    if loadFileName:\n",
    "        start_iteration=checkpoint['iteration']+1\n",
    "    \n",
    "    decoder_searcher=GreedySearchDecoder(encoder,decoder)\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration,n_iteration+1):\n",
    "        training_batch=batch2TrianData(voc,[random.choice(pairs) for _ in range(batch_size)])\n",
    "        \n",
    "        input_variable,lengths,target_variable,mask,max_target_len=training_batch\n",
    "\n",
    "        loss=train(input_variable,lengths,target_variable,mask,max_target_len,encoder,\n",
    "                  decoder,embedding,encoder_optimizer,decoder_optimizer,batch_size,clip)\n",
    "        \n",
    "        print_loss+=loss\n",
    "        \n",
    "        if iteration%print_every==0:\n",
    "            print_loss_avg=print_loss/print_every\n",
    "            print(\"Iteration:{}\\t Percent complete: {:.1f}%\\tAverage loss:{:.4f}\".format(\n",
    "                iteration,iteration/n_iteration*100,print_loss_avg))\n",
    "            print_loss=0\n",
    "        if iteration%save_every==0:\n",
    "            \n",
    "            test_inp,test_len,test_target,test_max_len=input_variable[:,0:1],lengths[0:1],target_variable[:,0:1],max_target_len\n",
    "\n",
    "            test_out,test_scores=decoder_searcher.forward(test_inp.to(device),test_len.to(device),test_max_len)\n",
    "\n",
    "            test_inp_list=[voc.index2word[i] for i in test_inp.numpy()[:,0]]\n",
    "            test_target_list=[voc.index2word[i] for i in test_target.numpy()[:,0]]\n",
    "            test_out_list=[voc.index2word[i] for i in test_out.cpu().numpy()]\n",
    "            \n",
    "            test_inp_str=\"\"\n",
    "            test_target_str=\"\"\n",
    "            test_out_str=\"\"\n",
    "            \n",
    "            for w in test_inp_list:test_inp_str+=w+\" \"\n",
    "            for w in test_target_list:test_target_str+=w+\" \"\n",
    "            for w in test_out_list:test_out_str+=w+\" \"\n",
    "                \n",
    "            print(\"=\"*30)\n",
    "            print(\"[In] : \"+test_inp_str)\n",
    "            print(\"[Target] : \"+test_target_str)\n",
    "            print(\"[Out] : \"+test_out_str)\n",
    "            \n",
    "            directory=os.path.join(save_dir,model_name,corpus_name,\"{}-{}_{}\".format(encoder_n_layers,decoder_n_layers,hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                    'iteration':iteration,\n",
    "                    'encoder':encoder.state_dict(),\n",
    "                    'decoder':decoder.state_dict(),\n",
    "                    'encoder_optimizer':encoder_optimizer.state_dict(),\n",
    "                    'decoder_optimizer':decoder_optimizer.state_dict(),\n",
    "                    'loss':loss,\n",
    "                    'voc_dict':voc.__dict__,\n",
    "                    'embedding':embedding.state_dict()\n",
    "                },os.path.join(directory,'{}_{}.tar'.format(iteration,\"checkpoint\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing encoder decoder done...\n"
     ]
    }
   ],
   "source": [
    "model_name=\"seq2seq_model\"\n",
    "attn_model=\"dot\"\n",
    " \n",
    "hidden_size=500\n",
    "encoder_n_layers=2\n",
    "decoder_n_layers=2\n",
    "dropout=0.1\n",
    "batch_size=256\n",
    "\n",
    "loadFileName=\"data/save/seq2seq_model/cornell movie-dialogs corpus/2-2_500/50000_checkpoint-baseline.tar\"## loading my pretrained model\n",
    "#loadFileName=None ##training your own model\n",
    "checkpoint_iter=4000\n",
    "\n",
    "if loadFileName:\n",
    "    checkpoint=torch.load(loadFileName)\n",
    "    encoder_sd=checkpoint[\"encoder\"]\n",
    "    decoder_sd=checkpoint[\"decoder\"]\n",
    "    encoder_optimizer_sd=checkpoint[\"encoder_optimizer\"]\n",
    "    decoder_optimizer_sd=checkpoint[\"decoder_optimizer\"]\n",
    "    embedding_sd=checkpoint[\"embedding\"]\n",
    "    voc.__dict__=checkpoint[\"voc_dict\"]\n",
    "embedding=nn.Embedding(voc.num_words,hidden_size)\n",
    "if loadFileName:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "encoder=EncoderRNN(hidden_size,embedding,encoder_n_layers,dropout)\n",
    "decoder=LuongAttnDecoderRNN(attn_model,embedding,hidden_size,voc.num_words,decoder_n_layers,dropout)\n",
    "if loadFileName:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "    \n",
    "encoder=encoder.to(device)\n",
    "decoder=decoder.to(device)\n",
    "print(\"Preparing encoder decoder done...\")\n",
    "clip=50.\n",
    "teacher_forcing_ratio=1.\n",
    "learning_rate=0.0001\n",
    "decoder_learning_ratio=5.0\n",
    "n_iteration=50000\n",
    "save_every=1000\n",
    "print_every=500\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "encoder_optimizer=torch.optim.Adam(encoder.parameters(),lr=learning_rate)\n",
    "decoder_optimizer=torch.optim.Adam(decoder.parameters(),lr=learning_rate*decoder_learning_ratio)\n",
    "\n",
    "if loadFileName:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing encoder decoder done...\n",
      "Initializing...\n",
      "Training...\n",
      "Iteration:500\t Percent complete: 1.0%\tAverage loss:4.0027\n",
      "Iteration:1000\t Percent complete: 2.0%\tAverage loss:3.3212\n",
      "==============================\n",
      "[In] : i just don t think it would work . EOS \n",
      "[Target] : why wouldn t it ? EOS PAD PAD PAD PAD \n",
      "[Out] : i know . EOS . EOS . EOS . EOS \n",
      "Iteration:1500\t Percent complete: 3.0%\tAverage loss:3.0322\n",
      "Iteration:2000\t Percent complete: 4.0%\tAverage loss:2.7486\n",
      "==============================\n",
      "[In] : right . well thanks . for the lift . EOS \n",
      "[Target] : no sweat . only do me a favor ? EOS \n",
      "[Out] : thank you . EOS me . EOS me . EOS \n",
      "Iteration:2500\t Percent complete: 5.0%\tAverage loss:2.4806\n",
      "Iteration:3000\t Percent complete: 6.0%\tAverage loss:2.1994\n",
      "==============================\n",
      "[In] : shit too bad we in base camp anyway . EOS \n",
      "[Target] : what you got there beers ? EOS PAD PAD PAD \n",
      "[Out] : what s the matter ? EOS deep dead . EOS \n",
      "Iteration:3500\t Percent complete: 7.0%\tAverage loss:1.9343\n",
      "Iteration:4000\t Percent complete: 8.0%\tAverage loss:1.6916\n",
      "==============================\n",
      "[In] : you re one of william s kids huh ? EOS \n",
      "[Target] : his only kid . EOS PAD PAD PAD PAD PAD \n",
      "[Out] : no . EOS me in the room . EOS EOS \n",
      "Iteration:4500\t Percent complete: 9.0%\tAverage loss:1.4602\n",
      "Iteration:5000\t Percent complete: 10.0%\tAverage loss:1.2475\n",
      "==============================\n",
      "[In] : it doesn t have to be like this ? EOS \n",
      "[Target] : oh god please u don t u ! EOS PAD \n",
      "[Out] : no sir . EOS my point EOS . EOS EOS \n",
      "Iteration:5500\t Percent complete: 11.0%\tAverage loss:1.0613\n",
      "Iteration:6000\t Percent complete: 12.0%\tAverage loss:0.8989\n",
      "==============================\n",
      "[In] : oh some insurance man . are you in ? EOS \n",
      "[Target] : give me that ! EOS PAD PAD PAD PAD PAD \n",
      "[Out] : give me that ! EOS ! EOS ! EOS ! \n",
      "Iteration:6500\t Percent complete: 13.0%\tAverage loss:0.7616\n",
      "Iteration:7000\t Percent complete: 14.0%\tAverage loss:0.6453\n",
      "==============================\n",
      "[In] : tell her i m very happy with it . EOS \n",
      "[Target] : he s scottish col . EOS PAD PAD PAD PAD \n",
      "[Out] : you re going through captain . EOS them . EOS \n",
      "Iteration:7500\t Percent complete: 15.0%\tAverage loss:0.5455\n",
      "Iteration:8000\t Percent complete: 16.0%\tAverage loss:0.4659\n",
      "==============================\n",
      "[In] : well . . . who are those guys ? EOS \n",
      "[Target] : what do they look like ? . . . EOS \n",
      "[Out] : what do you want ? EOS ? EOS EOS . \n",
      "Iteration:8500\t Percent complete: 17.0%\tAverage loss:0.4082\n",
      "Iteration:9000\t Percent complete: 18.0%\tAverage loss:0.3603\n",
      "==============================\n",
      "[In] : you re twenty two aren t you ray ? EOS \n",
      "[Target] : say what and so what . EOS PAD PAD PAD \n",
      "[Out] : say what ? EOS what EOS ? EOS EOS EOS \n",
      "Iteration:9500\t Percent complete: 19.0%\tAverage loss:0.3306\n",
      "Iteration:10000\t Percent complete: 20.0%\tAverage loss:0.3027\n",
      "==============================\n",
      "[In] : so what s up with you and dela ? EOS \n",
      "[Target] : what do you mean ? EOS PAD PAD PAD PAD \n",
      "[Out] : what do you mean ? EOS s dead . EOS \n",
      "Iteration:10500\t Percent complete: 21.0%\tAverage loss:0.2795\n",
      "Iteration:11000\t Percent complete: 22.0%\tAverage loss:0.2612\n",
      "==============================\n",
      "[In] : all right . what do we do now ? EOS \n",
      "[Target] : we wait for robert to wake up . EOS PAD \n",
      "[Out] : we wait for robert to wake up . EOS it \n",
      "Iteration:11500\t Percent complete: 23.0%\tAverage loss:0.2474\n",
      "Iteration:12000\t Percent complete: 24.0%\tAverage loss:0.2425\n",
      "==============================\n",
      "[In] : oh . shit . it s in the car EOS \n",
      "[Target] : what ? i thought you just EOS PAD PAD PAD \n",
      "[Out] : what ? i thought you just EOS . EOS EOS \n",
      "Iteration:12500\t Percent complete: 25.0%\tAverage loss:0.2334\n",
      "Iteration:13000\t Percent complete: 26.0%\tAverage loss:0.2294\n",
      "==============================\n",
      "[In] : don t tell me don t tell me ! EOS \n",
      "[Target] : edie it s EOS PAD PAD PAD PAD PAD PAD \n",
      "[Out] : edie it s EOS ! EOS it ! EOS EOS \n",
      "Iteration:13500\t Percent complete: 27.0%\tAverage loss:0.2188\n",
      "Iteration:14000\t Percent complete: 28.0%\tAverage loss:0.2147\n",
      "==============================\n",
      "[In] : put me down you son of a bitch ! EOS \n",
      "[Target] : walter ! EOS PAD PAD PAD PAD PAD PAD PAD \n",
      "[Out] : walter ! EOS bitch ! EOS ! EOS ! EOS \n",
      "Iteration:14500\t Percent complete: 29.0%\tAverage loss:0.2102\n",
      "Iteration:15000\t Percent complete: 30.0%\tAverage loss:0.2089\n",
      "==============================\n",
      "[In] : keep fuckin with me . watch what happens . EOS \n",
      "[Target] : all right then . EOS PAD PAD PAD PAD PAD \n",
      "[Out] : all right then . EOS me . EOS . EOS \n",
      "Iteration:15500\t Percent complete: 31.0%\tAverage loss:0.2080\n",
      "Iteration:16000\t Percent complete: 32.0%\tAverage loss:0.2012\n",
      "==============================\n",
      "[In] : cause you know goddamn well who i am . EOS \n",
      "[Target] : i don t know you . EOS PAD PAD PAD \n",
      "[Out] : i don t know you . EOS me . EOS \n",
      "Iteration:16500\t Percent complete: 33.0%\tAverage loss:0.1978\n",
      "Iteration:17000\t Percent complete: 34.0%\tAverage loss:0.1973\n",
      "==============================\n",
      "[In] : i d like to do your hair sometime . EOS \n",
      "[Target] : why ? EOS PAD PAD PAD PAD PAD PAD PAD \n",
      "[Out] : why ? EOS suck his own . EOS ? EOS \n",
      "Iteration:17500\t Percent complete: 35.0%\tAverage loss:0.1974\n",
      "Iteration:18000\t Percent complete: 36.0%\tAverage loss:0.1966\n",
      "==============================\n",
      "[In] : beidermeyer that s it what a mad man . EOS \n",
      "[Target] : he s a great poet . EOS PAD PAD PAD \n",
      "[Out] : he s a great poet . EOS him . EOS \n",
      "Iteration:18500\t Percent complete: 37.0%\tAverage loss:0.1937\n",
      "Iteration:19000\t Percent complete: 38.0%\tAverage loss:0.1904\n",
      "==============================\n",
      "[In] : come in joe . it s all right . EOS \n",
      "[Target] : hello joe . EOS PAD PAD PAD PAD PAD PAD \n",
      "[Out] : hello joe . EOS me . EOS EOS . EOS \n",
      "Iteration:19500\t Percent complete: 39.0%\tAverage loss:0.1900\n",
      "Iteration:20000\t Percent complete: 40.0%\tAverage loss:0.1916\n",
      "==============================\n",
      "[In] : oh i suppose you is a doctor homer ? EOS \n",
      "[Target] : almost . EOS PAD PAD PAD PAD PAD PAD PAD \n",
      "[Out] : almost . EOS a cab . EOS . EOS . \n",
      "Iteration:20500\t Percent complete: 41.0%\tAverage loss:0.1849\n",
      "Iteration:21000\t Percent complete: 42.0%\tAverage loss:0.1846\n",
      "==============================\n",
      "[In] : if you get a safe shot . . . EOS \n",
      "[Target] : i ll take it ! EOS PAD PAD PAD PAD \n",
      "[Out] : i ll take it ! EOS ! EOS ! EOS \n",
      "Iteration:21500\t Percent complete: 43.0%\tAverage loss:0.1839\n",
      "Iteration:22000\t Percent complete: 44.0%\tAverage loss:0.1818\n",
      "==============================\n",
      "[In] : what then ? robbery ? extortion ? kidnapping ! EOS \n",
      "[Target] : none of the above thank you . EOS PAD PAD \n",
      "[Out] : none of the above thank you . EOS the dark \n",
      "Iteration:22500\t Percent complete: 45.0%\tAverage loss:0.1811\n",
      "Iteration:23000\t Percent complete: 46.0%\tAverage loss:0.1832\n",
      "==============================\n",
      "[In] : this is the best we re gonna do . EOS \n",
      "[Target] : it ll have to do . EOS PAD PAD PAD \n",
      "[Out] : it ll have to do . EOS . EOS . \n",
      "Iteration:23500\t Percent complete: 47.0%\tAverage loss:0.1810\n",
      "Iteration:24000\t Percent complete: 48.0%\tAverage loss:0.1793\n",
      "==============================\n",
      "[In] : all i need is fifteen minutes a night . EOS \n",
      "[Target] : fifteen minutes ? EOS PAD PAD PAD PAD PAD PAD \n",
      "[Out] : fifteen minutes ? EOS this morning . EOS EOS EOS \n",
      "Iteration:24500\t Percent complete: 49.0%\tAverage loss:0.1801\n",
      "Iteration:25000\t Percent complete: 50.0%\tAverage loss:0.1784\n",
      "==============================\n",
      "[In] : mission control to chuck come in . . . EOS \n",
      "[Target] : you re late . EOS PAD PAD PAD PAD PAD \n",
      "[Out] : you re late . EOS . EOS . EOS . \n",
      "Iteration:25500\t Percent complete: 51.0%\tAverage loss:0.1781\n",
      "Iteration:26000\t Percent complete: 52.0%\tAverage loss:0.1777\n",
      "==============================\n",
      "[In] : smith where the hell have you been ? ! EOS \n",
      "[Target] : we have a situation here . . . EOS PAD \n",
      "[Out] : we have a situation here . . . EOS . \n",
      "Iteration:26500\t Percent complete: 53.0%\tAverage loss:0.1760\n",
      "Iteration:27000\t Percent complete: 54.0%\tAverage loss:0.1748\n",
      "==============================\n",
      "[In] : well what am i supposed to call you ? EOS \n",
      "[Target] : that s besides the point . EOS PAD PAD PAD \n",
      "[Out] : that s besides the point . EOS it up . \n",
      "Iteration:27500\t Percent complete: 55.0%\tAverage loss:0.1752\n",
      "Iteration:28000\t Percent complete: 56.0%\tAverage loss:0.1742\n",
      "==============================\n",
      "[In] : i thought it was okay where it was . EOS \n",
      "[Target] : it s much more personal in here . EOS PAD \n",
      "[Out] : it s much more personal in here . EOS EOS \n",
      "Iteration:28500\t Percent complete: 57.0%\tAverage loss:0.1748\n",
      "Iteration:29000\t Percent complete: 58.0%\tAverage loss:0.1742\n",
      "==============================\n",
      "[In] : do you ever regret not having a family ? EOS \n",
      "[Target] : not everybody s supposed to have a family . EOS \n",
      "[Out] : not everybody s supposed to have a family . EOS \n",
      "Iteration:29500\t Percent complete: 59.0%\tAverage loss:0.1750\n",
      "Iteration:30000\t Percent complete: 60.0%\tAverage loss:0.1725\n",
      "==============================\n",
      "[In] : never mind his excellency you gotta your pocketbook ? EOS \n",
      "[Target] : yes why ? EOS PAD PAD PAD PAD PAD PAD \n",
      "[Out] : yes why ? EOS me tomorrow ? EOS EOS EOS \n",
      "Iteration:30500\t Percent complete: 61.0%\tAverage loss:0.1721\n",
      "Iteration:31000\t Percent complete: 62.0%\tAverage loss:0.1711\n",
      "==============================\n",
      "[In] : he s your boss . he s not your EOS \n",
      "[Target] : i know i know . EOS PAD PAD PAD PAD \n",
      "[Out] : i know i know . EOS EOS . EOS . \n",
      "Iteration:31500\t Percent complete: 63.0%\tAverage loss:0.1724\n",
      "Iteration:32000\t Percent complete: 64.0%\tAverage loss:0.1722\n",
      "==============================\n",
      "[In] : decide to take a day off after all ? EOS \n",
      "[Target] : dad i want to see rod lane . EOS PAD \n",
      "[Out] : dad i want to see rod lane . EOS . \n",
      "Iteration:32500\t Percent complete: 65.0%\tAverage loss:0.1693\n",
      "Iteration:33000\t Percent complete: 66.0%\tAverage loss:0.1667\n",
      "==============================\n",
      "[In] : it was romantic . he s very romantic . EOS \n",
      "[Target] : so are you engaged or what ? EOS PAD PAD \n",
      "[Out] : so are you engaged or what ? EOS . EOS \n",
      "Iteration:33500\t Percent complete: 67.0%\tAverage loss:0.1702\n",
      "Iteration:34000\t Percent complete: 68.0%\tAverage loss:0.1695\n",
      "==============================\n",
      "[In] : i know what you re going to say . EOS \n",
      "[Target] : do you ? EOS PAD PAD PAD PAD PAD PAD \n",
      "[Out] : do you ? EOS me . EOS . EOS . \n",
      "Iteration:34500\t Percent complete: 69.0%\tAverage loss:0.1685\n",
      "Iteration:35000\t Percent complete: 70.0%\tAverage loss:0.1669\n",
      "==============================\n",
      "[In] : you don t drink like you used to . EOS \n",
      "[Target] : that s not a question . EOS PAD PAD PAD \n",
      "[Out] : that s not a question . EOS . EOS . \n",
      "Iteration:35500\t Percent complete: 71.0%\tAverage loss:0.1664\n",
      "Iteration:36000\t Percent complete: 72.0%\tAverage loss:0.1670\n",
      "==============================\n",
      "[In] : i don t owe them a goddamn thing . EOS \n",
      "[Target] : then why don t you testify ? EOS PAD PAD \n",
      "[Out] : then why don t you testify ? EOS EOS EOS \n",
      "Iteration:36500\t Percent complete: 73.0%\tAverage loss:0.1677\n",
      "Iteration:37000\t Percent complete: 74.0%\tAverage loss:0.1669\n",
      "==============================\n",
      "[In] : don t ever do that to me again . EOS \n",
      "[Target] : do what ? EOS PAD PAD PAD PAD PAD PAD \n",
      "[Out] : do what ? EOS ? EOS the call back . \n",
      "Iteration:37500\t Percent complete: 75.0%\tAverage loss:0.1664\n",
      "Iteration:38000\t Percent complete: 76.0%\tAverage loss:0.1666\n",
      "==============================\n",
      "[In] : he ll still be your son in law ! EOS \n",
      "[Target] : you see how much we have to say . EOS \n",
      "[Out] : you see how much we have to say . EOS \n",
      "Iteration:38500\t Percent complete: 77.0%\tAverage loss:0.1667\n",
      "Iteration:39000\t Percent complete: 78.0%\tAverage loss:0.1646\n",
      "==============================\n",
      "[In] : only the damn guy won t know it . EOS \n",
      "[Target] : what happens if i say no ? EOS PAD PAD \n",
      "[Out] : what happens if i say no ? EOS EOS ? \n",
      "Iteration:39500\t Percent complete: 79.0%\tAverage loss:0.1631\n",
      "Iteration:40000\t Percent complete: 80.0%\tAverage loss:0.1658\n",
      "==============================\n",
      "[In] : we re asking you to go to prison . EOS \n",
      "[Target] : but i ve never served a day . EOS PAD \n",
      "[Out] : but i ve never served a day . EOS . \n",
      "Iteration:40500\t Percent complete: 81.0%\tAverage loss:0.1652\n",
      "Iteration:41000\t Percent complete: 82.0%\tAverage loss:0.1635\n",
      "==============================\n",
      "[In] : is that a pretty good job fbi agent ? EOS \n",
      "[Target] : i think so . EOS PAD PAD PAD PAD PAD \n",
      "[Out] : i think so . EOS . EOS . EOS EOS \n",
      "Iteration:41500\t Percent complete: 83.0%\tAverage loss:0.1626\n",
      "Iteration:42000\t Percent complete: 84.0%\tAverage loss:0.1651\n",
      "==============================\n",
      "[In] : why they gotta make my nose so big ? EOS \n",
      "[Target] : look at my lips . EOS PAD PAD PAD PAD \n",
      "[Out] : look at my lips . EOS my lips . EOS \n",
      "Iteration:42500\t Percent complete: 85.0%\tAverage loss:0.1681\n",
      "Iteration:43000\t Percent complete: 86.0%\tAverage loss:0.1654\n",
      "==============================\n",
      "[In] : i thought i d give it to you . EOS \n",
      "[Target] : thank you . shall i . . . EOS PAD \n",
      "[Out] : thank you . shall i . . . EOS . \n",
      "Iteration:43500\t Percent complete: 87.0%\tAverage loss:0.1648\n",
      "Iteration:44000\t Percent complete: 88.0%\tAverage loss:0.1635\n",
      "==============================\n",
      "[In] : do you expect me to give myself up ? EOS \n",
      "[Target] : why not ? EOS PAD PAD PAD PAD PAD PAD \n",
      "[Out] : why not ? EOS go ? EOS EOS EOS . \n",
      "Iteration:44500\t Percent complete: 89.0%\tAverage loss:0.1627\n",
      "Iteration:45000\t Percent complete: 90.0%\tAverage loss:0.1614\n",
      "==============================\n",
      "[In] : wouldn t miss this for the world pal . EOS \n",
      "[Target] : who s this ? EOS PAD PAD PAD PAD PAD \n",
      "[Out] : who s this ? EOS s get there . EOS \n",
      "Iteration:45500\t Percent complete: 91.0%\tAverage loss:0.1628\n",
      "Iteration:46000\t Percent complete: 92.0%\tAverage loss:0.1607\n",
      "==============================\n",
      "[In] : that dog was mean before i met him . EOS \n",
      "[Target] : that dog ain t mean . EOS PAD PAD PAD \n",
      "[Out] : that dog ain t mean . EOS run . EOS \n",
      "Iteration:46500\t Percent complete: 93.0%\tAverage loss:0.1627\n",
      "Iteration:47000\t Percent complete: 94.0%\tAverage loss:0.1610\n",
      "==============================\n",
      "[In] : doctor acula ? i don t get it . EOS \n",
      "[Target] : u dr . acula u ! EOS PAD PAD PAD \n",
      "[Out] : u dr . acula u ! EOS EOS EOS EOS \n",
      "Iteration:47500\t Percent complete: 95.0%\tAverage loss:0.1636\n",
      "Iteration:48000\t Percent complete: 96.0%\tAverage loss:0.1607\n",
      "==============================\n",
      "[In] : frank don t you have something to say ? EOS \n",
      "[Target] : you re doing just fine . EOS PAD PAD PAD \n",
      "[Out] : you re doing just fine . EOS . EOS EOS \n",
      "Iteration:48500\t Percent complete: 97.0%\tAverage loss:0.1615\n",
      "Iteration:49000\t Percent complete: 98.0%\tAverage loss:0.1627\n",
      "==============================\n",
      "[In] : oh you have group access don t you ? EOS \n",
      "[Target] : yeah . . . ? EOS PAD PAD PAD PAD \n",
      "[Out] : yeah . . . ? EOS . EOS . EOS \n",
      "Iteration:49500\t Percent complete: 99.0%\tAverage loss:0.1639\n",
      "Iteration:50000\t Percent complete: 100.0%\tAverage loss:0.1613\n",
      "==============================\n",
      "[In] : hey can you sneak me on the lot ? EOS \n",
      "[Target] : sure . EOS PAD PAD PAD PAD PAD PAD PAD \n",
      "[Out] : sure . EOS a day . EOS . EOS . \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainIters(model_name,voc,pairs,encoder,decoder,encoder_optimizer,decoder_optimizer,\n",
    "          embedding,encoder_n_layers,decoder_n_layers,save_dir,n_iteration,batch_size,print_every,\n",
    "          save_every,clip,corpus_name,loadFileName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine . EOS\n"
     ]
    }
   ],
   "source": [
    "encoder.train(mode=False)\n",
    "decoder.train(mode=False)\n",
    "def chatbot_question(q):\n",
    "    q=normalizeString(q)\n",
    "    q_seq=[]\n",
    "    for w in q.split(\" \"):\n",
    "        if w not in voc.word2index:\n",
    "            raise ValueError(w,\"not in vocabulary.\")\n",
    "        q_seq.append(voc.word2index[w])\n",
    "    q_seq=np.array(q_seq)\n",
    "    q_length=np.array(len(q_seq))\n",
    "    q_seq=torch.LongTensor(np.expand_dims(q_seq,-1))\n",
    "    q_length=torch.LongTensor(np.expand_dims(q_length,-1))\n",
    "    q_seq=q_seq.to(device)\n",
    "    q_length=q_length.to(device)\n",
    "    \n",
    "    encoder_output,encoder_hidden=encoder.forward(q_seq,q_length)\n",
    "    \n",
    "    decoder_hidden=encoder_hidden[:decoder.n_layers]\n",
    "    decoder_input=torch.LongTensor(np.zeros((1,1))+SOS_token)\n",
    "    decoder_input=decoder_input.to(device)\n",
    "    \n",
    "    answer_tokens=[]\n",
    "    for t in range(MAX_LENGTH):\n",
    "        decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_output)\n",
    "        \n",
    "        token_score,token_idx=torch.max(decoder_output,dim=1)\n",
    "        answer_tokens.append(token_idx.cpu().numpy()[0])\n",
    "        \n",
    "        decoder_input=torch.unsqueeze(token_idx,1)\n",
    "        \n",
    "        if token_idx==EOS_token:\n",
    "            break\n",
    "    return ' '.join([voc.index2word[i] for i in answer_tokens])\n",
    "q=\"how are you ?\"\n",
    "a=chatbot_question(q)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Question] How are you? Frank\t[Bot] fine fine . EOS\n",
      "[Question] I'm fine. Mary.\t[Bot] so am i . . . EOS\n",
      "[Question] What's wrong?\t[Bot] nothing . EOS\n",
      "[Question] What happened?\t[Bot] i don t know ! EOS\n",
      "[Question] It's a nice day!\t[Bot] oh . . . EOS\n",
      "[Question] I like the weather.\t[Bot] i like such a different world . EOS\n",
      "[Question] You are such a sweet girl.\t[Bot] you think i better twenty a girl ? EOS\n",
      "[Question] He is the best teacher I have seen.\t[Bot] there s a lot of jack . EOS\n",
      "[Question] Let's do the cleaning.\t[Bot] we re getting married . EOS\n",
      "[Question] Let's go!\t[Bot] okay . let s go . EOS\n",
      "[Question] Can you pay for me?\t[Bot] that s okay . EOS\n",
      "[Question] I want that car.\t[Bot] what s this ? EOS\n",
      "[Question] It feels good to talk to a man.\t[Bot] you re a certain son son . EOS\n",
      "[Question] Being iron man is good.\t[Bot] faith . EOS\n",
      "[Question] I want to be the king.\t[Bot] that s the last week . EOS\n",
      "[Question] I want to have a cigarette.\t[Bot] i am . EOS\n"
     ]
    }
   ],
   "source": [
    "qs=[\"How are you? Frank\",\"I'm fine. Mary.\",\n",
    "    \"What's wrong?\",\"What happened?\",\n",
    "    \"It's a nice day!\",\"I like the weather.\",\n",
    "    \"You are such a sweet girl.\",\"He is the best teacher I have seen.\",\n",
    "    \"Let's do the cleaning.\",\"Let's go!\",\n",
    "   \"Can you pay for me?\",\"I want that car.\",\n",
    "    \"It feels good to talk to a man.\",\"Being iron man is good.\",\n",
    "    \"I want to be the king.\",\"I want to have a cigarette.\"]\n",
    "for q in qs:\n",
    "    a=chatbot_question(q)\n",
    "    print(\"[Question] \"+q,end=\"\\t\")\n",
    "    print(\"[Bot] \"+a)\n",
    "    #print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "18803547-4a43-4444-ab3b-60e9ddbf62ee": {
     "id": "18803547-4a43-4444-ab3b-60e9ddbf62ee",
     "prev": null,
     "regions": {
      "53490e53-84b0-401f-b0a1-90b1daf06c79": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "65b932b1-2187-45f8-9950-aded9ec6c933",
        "part": "whole"
       },
       "id": "53490e53-84b0-401f-b0a1-90b1daf06c79"
      }
     }
    },
    "27a8cd40-0862-4b07-8255-fb4b39fd38b6": {
     "id": "27a8cd40-0862-4b07-8255-fb4b39fd38b6",
     "prev": "97c38fda-77ae-46cd-bc44-e227db56bb80",
     "regions": {
      "d925002c-b498-43d7-92e0-9e1be0b382fe": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "45c9b2bd-d274-4ea3-9cff-9c82a6f86a53",
        "part": "whole"
       },
       "id": "d925002c-b498-43d7-92e0-9e1be0b382fe"
      }
     }
    },
    "7fa2d078-ac66-4508-a913-1e457a7197c9": {
     "id": "7fa2d078-ac66-4508-a913-1e457a7197c9",
     "prev": "27a8cd40-0862-4b07-8255-fb4b39fd38b6",
     "regions": {
      "32624543-0e8a-4da5-89ff-9fb5ea819a67": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6e83c80c-0b51-4067-8eae-e431aaea6560",
        "part": "whole"
       },
       "id": "32624543-0e8a-4da5-89ff-9fb5ea819a67"
      }
     }
    },
    "94614ac0-32aa-4e97-a951-2f92256d2fdc": {
     "id": "94614ac0-32aa-4e97-a951-2f92256d2fdc",
     "prev": "c15a163e-e565-42bb-a379-91083ccd2169",
     "regions": {
      "31661b4e-0f21-408b-92f1-9ea937cf663b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a1fd339a-7bdd-4dbf-8464-0f9ba2e3165a",
        "part": "whole"
       },
       "id": "31661b4e-0f21-408b-92f1-9ea937cf663b"
      }
     }
    },
    "97c38fda-77ae-46cd-bc44-e227db56bb80": {
     "id": "97c38fda-77ae-46cd-bc44-e227db56bb80",
     "prev": "e4f0cb75-307f-4d5a-8394-39d4d438aee5",
     "regions": {
      "8c2fe7a3-7259-4191-bbdf-13f2fddef1bb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3e949896-8814-4aa7-a64e-5c1d86a455cb",
        "part": "whole"
       },
       "id": "8c2fe7a3-7259-4191-bbdf-13f2fddef1bb"
      }
     }
    },
    "c15a163e-e565-42bb-a379-91083ccd2169": {
     "id": "c15a163e-e565-42bb-a379-91083ccd2169",
     "prev": "7fa2d078-ac66-4508-a913-1e457a7197c9",
     "regions": {
      "9918764f-c803-4b97-baa5-247eae39d1d1": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "066daf18-0bca-4814-856f-8252567f599e",
        "part": "whole"
       },
       "id": "9918764f-c803-4b97-baa5-247eae39d1d1"
      }
     }
    },
    "e4f0cb75-307f-4d5a-8394-39d4d438aee5": {
     "id": "e4f0cb75-307f-4d5a-8394-39d4d438aee5",
     "prev": "18803547-4a43-4444-ab3b-60e9ddbf62ee",
     "regions": {
      "e649317a-1523-4d9b-8d1f-0155e6951a66": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "5e01fa13-27dc-4f31-8b5c-a8ddb5d2eb52",
        "part": "whole"
       },
       "id": "e649317a-1523-4d9b-8d1f-0155e6951a66"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
